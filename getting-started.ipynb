{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load dependencies\n",
    "\n",
    "The following loads the necessary dependencies and checks the Python version (at runtime). ML-Agents Toolkit (v0.3 onwards) requires Python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:\n",
      "3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfig, EngineConfigurationChannel\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Python version:\")\n",
    "print(sys.version)\n",
    "\n",
    "# check Python version\n",
    "if (sys.version_info[0] < 3):\n",
    "    raise Exception(\"ERROR: ML-Agents Toolkit (v0.3 onwards) requires Python 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Start the environment\n",
    "`UnityEnvironment` launches and begins communication with the environment when instantiated.\n",
    "\n",
    "Environments contain _brains_ which are responsible for deciding the actions of their associated _agents_. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_configuration_channel = EngineConfigurationChannel()\n",
    "env_name=\"./Build/PoliceInt.exe\"\n",
    "env = UnityEnvironment(file_name=env_name, side_channels = [engine_configuration_channel])\n",
    "\n",
    "#Reset the environment\n",
    "env.reset()\n",
    "\n",
    "# Set the default brain to work with\n",
    "group_name = env.get_agent_groups()[0]\n",
    "group_spec = env.get_agent_group_spec(group_name)\n",
    "\n",
    "# Set the time scale of the engine\n",
    "engine_configuration_channel.set_configuration_parameters(time_scale = 3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Examine the observation and state spaces\n",
    "We can reset the environment to be provided with an initial set of observations and states for all the agents within the environment. In ML-Agents, _states_ refer to a vector of variables corresponding to relevant aspects of the environment for an agent. Likewise, _observations_ refer to a set of relevant pixel-wise visuals for an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations :  3\n",
      "Is there a visual observation ? True\n",
      "Agent visual observation looks like:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the state of the agents\n",
    "step_result = env.get_step_result(group_name)\n",
    "\n",
    "# Examine the number of observations per Agent\n",
    "print(\"Number of observations : \", len(group_spec.observation_shapes))\n",
    "\n",
    "# Is there a visual observation ?\n",
    "vis_obs = any([len(shape) == 3 for shape in group_spec.observation_shapes])\n",
    "print(\"Is there a visual observation ?\", vis_obs)\n",
    "\n",
    "# Examine the visual observations\n",
    "if vis_obs:\n",
    "    vis_obs_index = next(i for i,v in enumerate(group_spec.observation_shapes) if len(v) == 3)\n",
    "    print(\"Agent visual observation looks like:\")\n",
    "    obs = step_result.obs[vis_obs_index]\n",
    "    plt.imshow(obs[0,:,:,:])\n",
    "else:\n",
    "    # Examine the state space for the first observation for the first agent\n",
    "    print(\"First Agent observation looks like: \\n{}\".format(step_result.obs[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Take random actions in the environment\n",
    "Once we restart an environment, we can step the environment forward and provide actions to all of the agents within the environment. Here we simply choose random actions based on the `action_space_type` of the default brain.\n",
    "\n",
    "Once this cell is executed, 10 messages will be printed that detail how much reward will be accumulated for the next 10 episodes. The Unity environment will then pause, waiting for further signals telling it what to do next. Thus, not seeing any animation is expected when running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward this episode: -10.379999697208405 Episode 0\n",
      "Total reward this episode: -10.939999863505363 Episode 1\n",
      "Total reward this episode: -15.509999826550484 Episode 2\n",
      "Total reward this episode: -10.939999863505363 Episode 3\n",
      "Total reward this episode: -13.320000097155571 Episode 4\n",
      "Total reward this episode: -2.799999602138996 Episode 5\n",
      "Total reward this episode: -10.360000193119049 Episode 6\n",
      "Total reward this episode: 0.07000012695789337 Episode 7\n",
      "Total reward this episode: -11.670000277459621 Episode 8\n",
      "Total reward this episode: -11.670000277459621 Episode 9\n",
      "Total reward this episode: 0.9900000095367432 Episode 10\n",
      "Total reward this episode: -2.249999664723873 Episode 11\n",
      "Total reward this episode: -10.45000034570694 Episode 12\n",
      "Total reward this episode: -10.45000034570694 Episode 13\n",
      "Total reward this episode: -10.939999863505363 Episode 14\n",
      "Total reward this episode: -2.0499996840953827 Episode 15\n",
      "Total reward this episode: -11.179999805986881 Episode 16\n",
      "Total reward this episode: 0.050000086426734924 Episode 17\n",
      "Total reward this episode: -7.039999149739742 Episode 18\n",
      "Total reward this episode: -10.939999863505363 Episode 19\n",
      "Total reward this episode: -10.47999968379736 Episode 20\n",
      "Total reward this episode: -11.650000214576721 Episode 21\n",
      "Total reward this episode: -11.849999994039536 Episode 22\n",
      "Total reward this episode: -11.8399997651577 Episode 23\n",
      "Total reward this episode: -14.539999470114708 Episode 24\n",
      "Total reward this episode: -2.1999996677041054 Episode 25\n",
      "Total reward this episode: -1.3199997320771217 Episode 26\n",
      "Total reward this episode: -10.939999863505363 Episode 27\n",
      "Total reward this episode: -10.939999863505363 Episode 28\n",
      "Total reward this episode: -2.0499996840953827 Episode 29\n",
      "Total reward this episode: -12.420000195503235 Episode 30\n",
      "Total reward this episode: -11.479999773204327 Episode 31\n",
      "Total reward this episode: -20.569999307394028 Episode 32\n",
      "Total reward this episode: -10.370000422000885 Episode 33\n",
      "Total reward this episode: 0.1100001111626625 Episode 34\n",
      "Total reward this episode: -11.789999969303608 Episode 35\n",
      "Total reward this episode: -13.889999739825726 Episode 36\n",
      "Total reward this episode: -10.45000034570694 Episode 37\n",
      "Total reward this episode: -14.619999200105667 Episode 38\n",
      "Total reward this episode: -10.939999863505363 Episode 39\n",
      "Total reward this episode: -14.059999786317348 Episode 40\n",
      "Total reward this episode: -10.939999863505363 Episode 41\n",
      "Total reward this episode: -13.129999592900276 Episode 42\n",
      "Total reward this episode: -0.7499998286366463 Episode 43\n",
      "Total reward this episode: -10.45000034570694 Episode 44\n",
      "Total reward this episode: -10.45000034570694 Episode 45\n",
      "Total reward this episode: -15.52999933063984 Episode 46\n",
      "Total reward this episode: -10.939999863505363 Episode 47\n",
      "Total reward this episode: -10.939999863505363 Episode 48\n",
      "Total reward this episode: -10.939999863505363 Episode 49\n",
      "Total reward this episode: -15.279999159276485 Episode 50\n",
      "Total reward this episode: -10.47999968379736 Episode 51\n",
      "Total reward this episode: -11.670000277459621 Episode 52\n",
      "Total reward this episode: -12.539999887347221 Episode 53\n",
      "Total reward this episode: 0.06000007688999176 Episode 54\n",
      "Total reward this episode: -11.670000277459621 Episode 55\n",
      "Total reward this episode: -11.670000277459621 Episode 56\n",
      "Total reward this episode: -13.869999282062054 Episode 57\n",
      "Total reward this episode: -15.269999884068966 Episode 58\n",
      "Total reward this episode: -13.860000006854534 Episode 59\n",
      "Total reward this episode: -11.810000032186508 Episode 60\n",
      "Total reward this episode: 0.8099999949336052 Episode 61\n",
      "Total reward this episode: -10.45000034570694 Episode 62\n",
      "Total reward this episode: -10.45000034570694 Episode 63\n",
      "Total reward this episode: -15.289999388158321 Episode 64\n",
      "Total reward this episode: -10.939999863505363 Episode 65\n",
      "Total reward this episode: -15.359999842941761 Episode 66\n",
      "Total reward this episode: -12.389999903738499 Episode 67\n",
      "Total reward this episode: -10.929999634623528 Episode 68\n",
      "Total reward this episode: -18.239999264478683 Episode 69\n",
      "Total reward this episode: -10.939999863505363 Episode 70\n",
      "Total reward this episode: -2.0999996811151505 Episode 71\n",
      "Total reward this episode: -13.87999951094389 Episode 72\n",
      "Total reward this episode: 0.5600000470876694 Episode 73\n",
      "Total reward this episode: 0.13000009208917618 Episode 74\n",
      "Total reward this episode: -10.370000422000885 Episode 75\n",
      "Total reward this episode: 0.07000012695789337 Episode 76\n",
      "Total reward this episode: -11.970000244677067 Episode 77\n",
      "Total reward this episode: -10.939999863505363 Episode 78\n",
      "Total reward this episode: -11.650000214576721 Episode 79\n",
      "Total reward this episode: -12.409999966621399 Episode 80\n",
      "Total reward this episode: -10.939999863505363 Episode 81\n",
      "Total reward this episode: -2.0499996840953827 Episode 82\n",
      "Total reward this episode: -14.609999924898148 Episode 83\n",
      "Total reward this episode: -10.939999863505363 Episode 84\n",
      "Total reward this episode: -15.479999139904976 Episode 85\n",
      "Total reward this episode: -10.939999863505363 Episode 86\n",
      "Total reward this episode: -10.939999863505363 Episode 87\n",
      "Total reward this episode: -10.939999863505363 Episode 88\n",
      "Total reward this episode: -13.129999592900276 Episode 89\n",
      "Total reward this episode: -11.820000261068344 Episode 90\n",
      "Total reward this episode: -10.939999863505363 Episode 91\n",
      "Total reward this episode: -12.420000195503235 Episode 92\n",
      "Total reward this episode: -10.939999863505363 Episode 93\n",
      "Total reward this episode: -13.87999951094389 Episode 94\n",
      "Total reward this episode: -10.939999863505363 Episode 95\n",
      "Total reward this episode: -10.360000193119049 Episode 96\n",
      "Total reward this episode: -11.670000277459621 Episode 97\n",
      "Total reward this episode: -12.669999413192272 Episode 98\n",
      "Total reward this episode: 0.8300000354647636 Episode 99\n",
      "Total reward this episode: -10.379999697208405 Episode 100\n",
      "Total reward this episode: -12.420000195503235 Episode 101\n",
      "Total reward this episode: -11.670000277459621 Episode 102\n",
      "Total reward this episode: -11.670000277459621 Episode 103\n",
      "Total reward this episode: -10.939999863505363 Episode 104\n",
      "Total reward this episode: -14.419999979436398 Episode 105\n",
      "Total reward this episode: -12.22999969124794 Episode 106\n",
      "Total reward this episode: -11.089999847114086 Episode 107\n",
      "Total reward this episode: -16.04999953508377 Episode 108\n",
      "Total reward this episode: -11.800000198185444 Episode 109\n",
      "Total reward this episode: -10.939999863505363 Episode 110\n",
      "Total reward this episode: -11.110000111162663 Episode 111\n",
      "Total reward this episode: -15.299999617040157 Episode 112\n",
      "Total reward this episode: -13.139999821782112 Episode 113\n",
      "Total reward this episode: 0.8300000354647636 Episode 114\n",
      "Total reward this episode: -15.999999739229679 Episode 115\n",
      "Total reward this episode: -10.379999697208405 Episode 116\n",
      "Total reward this episode: -10.360000193119049 Episode 117\n",
      "Total reward this episode: -10.360000193119049 Episode 118\n",
      "Total reward this episode: -11.829999536275864 Episode 119\n",
      "Total reward this episode: -13.150000050663948 Episode 120\n",
      "Total reward this episode: -10.939999863505363 Episode 121\n",
      "Total reward this episode: -13.159999884665012 Episode 122\n",
      "Total reward this episode: -13.279999576508999 Episode 123\n",
      "Total reward this episode: -12.559999950230122 Episode 124\n",
      "Total reward this episode: -12.420000195503235 Episode 125\n",
      "Total reward this episode: 0.9900000095367432 Episode 126\n",
      "Total reward this episode: -11.019999593496323 Episode 127\n",
      "Total reward this episode: -11.660000048577785 Episode 128\n",
      "Total reward this episode: -11.800000198185444 Episode 129\n",
      "Total reward this episode: -12.420000195503235 Episode 130\n",
      "Total reward this episode: -1.1399997919797897 Episode 131\n",
      "Total reward this episode: -10.45000034570694 Episode 132\n",
      "Total reward this episode: -10.45000034570694 Episode 133\n",
      "Total reward this episode: -21.239998936653137 Episode 134\n",
      "Total reward this episode: -10.939999863505363 Episode 135\n",
      "Total reward this episode: -11.07999961823225 Episode 136\n",
      "Total reward this episode: -11.660000048577785 Episode 137\n",
      "Total reward this episode: -11.660000048577785 Episode 138\n",
      "Total reward this episode: -5.9899992644786835 Episode 139\n",
      "Total reward this episode: -12.420000195503235 Episode 140\n",
      "Total reward this episode: -12.409999966621399 Episode 141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward this episode: -2.16999963670969 Episode 142\n",
      "Total reward this episode: -4.239999413490295 Episode 143\n",
      "Total reward this episode: -12.400000132620335 Episode 144\n",
      "Total reward this episode: -14.059999786317348 Episode 145\n",
      "Total reward this episode: 0.8099999949336052 Episode 146\n",
      "Total reward this episode: -10.939999863505363 Episode 147\n",
      "Total reward this episode: -10.370000422000885 Episode 148\n",
      "Total reward this episode: -13.929999306797981 Episode 149\n",
      "Total reward this episode: -11.479999773204327 Episode 150\n",
      "Total reward this episode: -14.639999657869339 Episode 151\n",
      "Total reward this episode: -10.939999863505363 Episode 152\n",
      "Total reward this episode: -8.399998992681503 Episode 153\n",
      "Total reward this episode: 0.12000010162591934 Episode 154\n",
      "Total reward this episode: -2.349999651312828 Episode 155\n",
      "Total reward this episode: -13.150000050663948 Episode 156\n",
      "Total reward this episode: -11.650000214576721 Episode 157\n",
      "Total reward this episode: -10.379999697208405 Episode 158\n",
      "Total reward this episode: -12.579999454319477 Episode 159\n",
      "Total reward this episode: -10.939999863505363 Episode 160\n",
      "Total reward this episode: 0.09000010788440704 Episode 161\n",
      "Total reward this episode: -11.970000244677067 Episode 162\n",
      "Total reward this episode: -10.939999863505363 Episode 163\n",
      "Total reward this episode: -12.939999647438526 Episode 164\n",
      "Total reward this episode: -10.47999968379736 Episode 165\n",
      "Total reward this episode: -13.150000050663948 Episode 166\n",
      "Total reward this episode: -13.139999821782112 Episode 167\n",
      "Total reward this episode: -11.179999805986881 Episode 168\n",
      "Total reward this episode: -10.939999863505363 Episode 169\n",
      "Total reward this episode: -16.759999491274357 Episode 170\n",
      "Total reward this episode: -10.939999863505363 Episode 171\n",
      "Total reward this episode: -1.3799997344613075 Episode 172\n",
      "Total reward this episode: -14.609999924898148 Episode 173\n",
      "Total reward this episode: -10.47999968379736 Episode 174\n",
      "Total reward this episode: -10.939999863505363 Episode 175\n",
      "Total reward this episode: -16.749999657273293 Episode 176\n",
      "Total reward this episode: -10.939999863505363 Episode 177\n",
      "Total reward this episode: -10.939999863505363 Episode 178\n",
      "Total reward this episode: -2.3699996173381805 Episode 179\n",
      "Total reward this episode: -11.179999805986881 Episode 180\n",
      "Total reward this episode: -0.7099998071789742 Episode 181\n",
      "Total reward this episode: -10.45000034570694 Episode 182\n",
      "Total reward this episode: -10.45000034570694 Episode 183\n",
      "Total reward this episode: -16.769999720156193 Episode 184\n",
      "Total reward this episode: -12.51999942958355 Episode 185\n",
      "Total reward this episode: -21.869999162852764 Episode 186\n",
      "Total reward this episode: -12.420000195503235 Episode 187\n",
      "Total reward this episode: -13.32999937236309 Episode 188\n",
      "Total reward this episode: -13.869999282062054 Episode 189\n",
      "Total reward this episode: -12.939999647438526 Episode 190\n",
      "Total reward this episode: -11.179999805986881 Episode 191\n",
      "Total reward this episode: -14.619999200105667 Episode 192\n",
      "Total reward this episode: -11.169999577105045 Episode 193\n",
      "Total reward this episode: -13.32999937236309 Episode 194\n",
      "Total reward this episode: -12.559999950230122 Episode 195\n",
      "Total reward this episode: -10.379999697208405 Episode 196\n",
      "Total reward this episode: -10.360000193119049 Episode 197\n",
      "Total reward this episode: -11.670000277459621 Episode 198\n"
     ]
    },
    {
     "ename": "UnityTimeOutException",
     "evalue": "The Unity environment took too long to respond. Make sure that :\n\t The environment does not need user interaction to launch\n\t The Agents are linked to the appropriate Brains\n\t The environment and the Python interface have compatible versions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnityTimeOutException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9bb1241fcbda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbranch_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_agents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbranch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mstep_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_step_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mepisode_rewards\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mstep_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tmood\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\mlagents_envs\\timers.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mhierarchical_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tmood\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\mlagents_envs\\environment.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[0mstep_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generate_step_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_env_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mhierarchical_timer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"communicator.exchange\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexchange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mUnityCommunicationException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Communicator has stopped.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tmood\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\mlagents_envs\\rpc_communicator.py\u001b[0m in \u001b[0;36mexchange\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mmessage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munity_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoll_for_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tmood\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\mlagents_envs\\rpc_communicator.py\u001b[0m in \u001b[0;36mpoll_for_timeout\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout_wait\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             raise UnityTimeOutException(\n\u001b[1;32m---> 91\u001b[1;33m                 \u001b[1;34m\"The Unity environment took too long to respond. Make sure that :\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m                 \u001b[1;34m\"\\t The environment does not need user interaction to launch\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m                 \u001b[1;34m\"\\t The Agents are linked to the appropriate Brains\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnityTimeOutException\u001b[0m: The Unity environment took too long to respond. Make sure that :\n\t The environment does not need user interaction to launch\n\t The Agents are linked to the appropriate Brains\n\t The environment and the Python interface have compatible versions."
     ]
    }
   ],
   "source": [
    "for episode in range(1000000):\n",
    "    env.reset()\n",
    "    step_result = env.get_step_result(group_name)\n",
    "    done = False\n",
    "    episode_rewards = 0\n",
    "    while not done:\n",
    "        action_size = group_spec.action_size\n",
    "        if group_spec.is_action_continuous():\n",
    "            action = np.random.randn(step_result.n_agents(), group_spec.action_size)\n",
    "            \n",
    "        if group_spec.is_action_discrete():\n",
    "            branch_size = group_spec.discrete_action_branches\n",
    "            action = np.column_stack([np.random.randint(0, branch_size[i], size=(step_result.n_agents())) for i in range(len(branch_size))])\n",
    "        env.set_actions(group_name, action)\n",
    "        env.step()\n",
    "        step_result = env.get_step_result(group_name)\n",
    "        episode_rewards += step_result.reward[0]\n",
    "        done = step_result.done[0]\n",
    "    print(\"Total reward this episode: {}\".format(episode_rewards)+\" Episode \"+ str(episode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Close the environment when finished\n",
    "When we are finished using an environment, we can close it with the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "\n",
     "#%env_name = \"PoliceInt.exe\"  # Name of the Unity environment binary to launch\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
